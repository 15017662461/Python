## Numpy

import numpy as np

### 创建数组

#### np.array 给出数组所有项

np.array用于创建数组，需要给出数组的每一项的内容。可以创建一维数组也可以创建多维数组

```python
# 创建一维数组
a = np.array([1,2,3,45])
# 创建二维数组
b = np.array([1,2,3,4],[5,6,7,8])
```



#### np.arange 类似range方式创建

np.arange类似range方式创建数组。接受三个参数，第一个参数表示起始数字，第二个参数表示结束参数（不包含），第三个参数表示步长

```python
# 创建一个0~10(包含)的数组，间隔为0.5
a = np.arange(0,11,0.5)
```



#### np.linspace 创建等差数组

np.linspace 创建等差数组，接受三个参数，第一个参数表示起始数字，第二个参数表示结束参数（**包含**），第三个参数表示步长，还可以接受第四个参数endpoint=False表示不包含结束参数

```python
# 包含结束参数的等差数组
a = np.linspace(1,10,11) # a = [1.,1.9]
# 不包含结束参数的等差数组
b = 
```



#### np.logspace 创建等比数组

np.logspace创建等比数组与常规方式不同，它是根据等差数组的结果进行的，也就是说通过base**等差数组的结果得到等比数列

如下例所示：生成的是base2**等差数列(1,5)数量为10个的等比数列：

```python
# 等比数列
print(np.logspace(1, 5, base=2, num=10)) # [ 2.          2.72158     3.70349885  5.0396842   6.85795186  9.33223232
 12.69920842 17.28095582 23.51575188 32.]
# 相对应的等差数列
print(2 ** np.linspace(1,5,10))
```



#### np.zeros 创建全为0的数组

np.zeros创建全为0的数组，接受一个列表参数，列表的第一项为多少行，第二项为多少列

```python
# 创建一个4行5列的数组
np.zeros([4, 5])
''' 
[[0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0.]] 
'''
```



#### np.ones 创建全为1的数组

np.ones创建全为1的数组，接受一个列表参数，列表的第一项为多少行，第二项为多少列

```python
# 创建一个4行5列的数组
np.ones([4, 5])
''' 
[[1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1.]] 
'''
```



#### np.eye 创建单位矩阵（对角线为1，其他全为0）

np.eye 创建单位矩阵（对角线为1），由于单位矩阵行数=列数，所以只接受一个参数，表示多少行或者多少列

```python
np.eye(5)
'''
[[1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1.]]
'''
```



#### np.diag 创建对角矩阵（对角线之外的位置都为0）

np.diag 创建对角矩阵，接受一个列表参数，列表内部是对角线上的元素

```python
np.diag([4, 5, 8, 10])
"""
[[ 4  0  0  0]
 [ 0  5  0  0]
 [ 0  0  8  0]
 [ 0  0  0 10]]
"""
```



### np创建的数组的优点

**最大的优点就是创建出来的是矩阵，+-\*/直接作用于矩阵中的全部元素**

```python
np.eye(5) + 2
"""
[[3. 2. 2. 2. 2.]
 [2. 3. 2. 2. 2.]
 [2. 2. 3. 2. 2.]
 [2. 2. 2. 3. 2.]
 [2. 2. 2. 2. 3.]]
"""
np.eye(5) - 3
"""
[[-2. -3. -3. -3. -3.]
 [-3. -2. -3. -3. -3.]
 [-3. -3. -2. -3. -3.]
 [-3. -3. -3. -2. -3.]
 [-3. -3. -3. -3. -2.]]
"""
np.eye(5) * 2
"""
[[2. 0. 0. 0. 0.]
 [0. 2. 0. 0. 0.]
 [0. 0. 2. 0. 0.]
 [0. 0. 0. 2. 0.]
 [0. 0. 0. 0. 2.]]
"""
np.eye(5) / 2
"""
[[0.5 0.  0.  0.  0. ]
 [0.  0.5 0.  0.  0. ]
 [0.  0.  0.5 0.  0. ]
 [0.  0.  0.  0.5 0. ]
 [0.  0.  0.  0.  0.5]]
"""
```



### np数组的属性

#### shape 形状

shape形状描述的是数组有几行几列，返回的是一个元组形式：(行，列)

```python
a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print(a.shape)
# (3, 3)
```



#### ndim 维度

ndim 维度，也就是几维数组，或者可以理解为shape返回的元组中有几个数字：

```python
a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])print(a.ndim)# 2
```



#### size 大小

size 大小，也就是数组中有几个数字

```python
a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])print(a.size)# 9
```



#### dtype 数据类型

dtype 数据类型，也就是数组中的元素都是什么数据类型的

```python
a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print(a.dtype)
# int32
```





### 改变数组形状 

可以将数组行列发生改变或者维度发生改变

+ 行列改变（返回新数组，原数组不发生改变）：xxx.reshape(行，列) **注意会返回一个新数组，原数组不会发生改变**,如果只确定一个数字（行或者列），不确定的数字可以使用-1代替，程序将会自动计算

+ + ```python
    arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
    """arr = [[ 1  2  3]
     [ 4  5  6]
     [ 7  8  9]
     [10 11 12]]"""
    arr = arr.reshape(2,6)
    """
    arr = [[ 1  2  3  4  5  6]
     [ 7  8  9 10 11 12]]
    """
    ```

+ 行列改变（不返回新数组，原数组发生改变）：xxx.resize(行，列) **注意不会返回一个新数组，原数组会发生改变**

+ + ```python
    arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])"""arr = [[ 1  2  3] [ 4  5  6] [ 7  8  9] [10 11 12]]"""arr.resize(2,6)"""arr = [[ 1  2  3  4  5  6] [ 7  8  9 10 11 12]]"""
    ```



### 展开数组

+ xxx.ravel() 展开数组，也就是将数组展开成为一维数组。注意会返回一个展开后的新数组，原数组不发生改变.可以接受一个参数order当为'F'时纵向展开，不填写或者为'T'时横向展开.**展开后进行元素替换会改变xxx的值**

```python
arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])"""arr = [[ 1  2  3] [ 4  5  6] [ 7  8  9] [10 11 12]]"""arr = arr.ravel()"""arr = [ 1  2  3  4  5  6  7  8  9 10 11 12]"""arr = arr.ravel(order = 'F')"""arr = [ 1 4 7 10 2 5 8 11 3 6 9 12]"""arr.ravel()[0] = 100"""arr = [[ 100  2  3] [ 4  5  6] [ 7  8  9] [10 11 12]]"""
```

+ xxx.flattern() 展开数组，也就是将数组展开成为一维数组。注意会返回一个展开后的新数组，原数组不发生改变.可以接受一个参数order当为'F'时纵向展开，不填写或者为'T'时横向展开.**展开后进行元素替换不会改变xx的值**

```python
arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
"""arr = [[ 1  2  3]
 [ 4  5  6]
 [ 7  8  9]
 [10 11 12]]"""
arr = arr.flattern()
"""
arr = [ 1  2  3  4  5  6  7  8  9 10 11 12]
"""
arr = arr.flattern(order = 'F')
"""
arr = [ 1 4 7 10 2 5 8 11 3 6 9 12]
"""
arr.flattern()[0] = 100
"""arr = [[ 1  2  3]
 [ 4  5  6]
 [ 7  8  9]
 [10 11 12]]"""
```

+ 还可以使用上面的xxx.reshape(-1),来进行数组的展开。**展开后进行元素替换也会改变xxx的值**

```python
arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
"""arr = [[ 1  2  3]
 [ 4  5  6]
 [ 7  8  9]
 [10 11 12]]"""
arr = arr.reshape(-1)
"""
arr = [ 1  2  3  4  5  6  7  8  9 10 11 12]
"""
arr.arr.reshape(-1)[0] = 100
"""arr = [[ 100  2  3]
 [ 4  5  6]
 [ 7  8  9]
 [10 11 12]]"""
```



### 数组合并

#### 横向合并（行数相同，行与行合并）

np.hstack([数组1，数组2]),**注意合并的两个数组行数要相同**

```python
data1 = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 10, 10]]data2 = [[11, 12], [14, 15], [17, 18], [20, 20]]a = np.hstack([data1, data2])"""a = [[ 1  2  3 11 12] [ 4  5  6 14 15] [ 7  8  9 17 18] [10 10 10 20 20]] """
```



#### 纵向合并（列数相同，列与列合并）

np.vstack([数组1，数组2]),**注意合并的连个数组列数要相同**

```python
data1 = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 10, 10]]data3 = [[21, 21, 21], [22, 22, 22]]b = np.vstack([data1, data3])"""b = [[ 1  2  3] [ 4  5  6] [ 7  8  9] [10 10 10] [21 21 21] [22 22 22]]"""
```



#### 综合合并

np.concatenate通过axis=1或者0来控制横向合并还是纵向合并。**axis=1表示横向合并，行数要相同；axis=0表示纵向合并，列数要相同**

```python
data1 = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 10, 10]]data2 = [[11, 12], [14, 15], [17, 18], [20, 20]]data3 = [[21, 21, 21], [22, 22, 22]]a = np.concatenate((data1, data2), axis=1)b = np.concatenate([data1, data3], axis=0)"""a = [[ 1  2  3 11 12] [ 4  5  6 14 15] [ 7  8  9 17 18] [10 10 10 20 20]] b = [[ 1  2  3] [ 4  5  6] [ 7  8  9] [10 10 10] [21 21 21] [22 22 22]]"""
```



### 数组自身复制

np.tile(原型数组，(纵向复制几次，横向复制几次))

```python
arr1 = np.array([[1, 2, 3], [4, 5, 6]])
a = np.tile(arr1, (3, 2))
'''
a = 
[[1 2 3 1 2 3]
 [4 5 6 4 5 6]
 [1 2 3 1 2 3]
 [4 5 6 4 5 6]
 [1 2 3 1 2 3]
 [4 5 6 4 5 6]]
'''
```



### 数组的广播机制

对于数学上的矩阵相加，需要保证两个矩阵的行数和列数都要相同，在python中如果两个矩阵相加可以通过广播机制来使得两个数组行列数相同后再进行相加

行数或者列数少的矩阵会自动进行复制补全：

```python
# 行补全
arr1 = np.array([[1, 2, 3], [4, 5, 6]])
arr2 = np.array([1, 2, 3])
print(arr1 + arr2)
'''
[[1,2,3]
[4,5,6]]
+ 
[[1,2,3]
[1,2,3]]
= 
[[2 4 6]
[5 7 9]]
'''
# 列补全
arr1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
arr2 = np.array([[1], [2], [3]])
print(arr1 + arr2)
'''
[[1,2,3]
[4,5,6]
[7,8,9]]
+
[[1,1,1]
[2,2,2]
[3,3,3]]
=
[[ 2  3  4]
 [ 6  7  8]
 [10 11 12]]
'''
```



### 数组运算

+ 加法：np.add（数组1，数组2）
+ 减法：np.subtract(被减数组，减去的数组)
+ 乘法：np.multiply(数组1，数组2)
+ 除法：np.divide(被除数组，除数组)
+ 幂运算：np.power(数组，幂次)



### 数组去重

np.unique(数组)



### 排序与搜索

+ 排序（升序）：np.sort(数组)  直接返回排序后的数组
+ 排序（降序）：np.sort(数组，reverse=True)， 直接返回排序后的数组
+ 排序（返回排序后的原来的索引位置）：np.argsort(数组)，返回排序后原来的索引位置
+ 返回数组中的最大/小值：数组.max()/数组.min()
+ 返回数组中的最大/小值的索引：数组.argmax()/数组.argmin()



### 数组每一项的if操作

+ np.where(条件，为True时的内容，为False时的内容).

  ```python
  # 对于arr1每一项进行处理，若大于3则显示原来的内容，若小于3则显示0arr1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])print(np.where(arr1 > 3, arr1, 0))'''[[0 0 0] [4 5 6] [7 8 9]]'''
  ```

+ np.extract(条件，为True的内容)。不同的是只会显示为True的内容，False内容消失

  ```python
  # 对于arr1每一项进行处理，只显示大于3 的内容arr1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])print(np.extract(arr1 > 3, arr1))'''[4 5 6 7 8 9]'''
  ```

  

### 文件读取

+ np.genfromtxt(文件名，delimiter=','，skip_header=1) skip_header表示忽略开头多少行
+ np.loadtxt(文件名，delimiter=','，dtype='str') dtype表示数据类型



### 文件存储

np.savetxt(文件名，要存储的数据，delimiter=','，fmt=格式（例如：fmt='%.4f'保留四位小数）)



### 生成随机数

+ 产生0到1之间的浮点数：np.random.random((几行，几列)) 

  ```python
  a = np.random.random((3, 4))
  '''
  [[0.35493088 0.16638072 0.76608625 0.19840225]
   [0.4536949  0.16413746 0.09360324 0.50531166]
   [0.41576202 0.56861802 0.13120204 0.33859004]]
  '''
  ```

+ 产生均匀分布的0~1之间的浮点数：（也就是每个数出现的概率是一样的）：np.random.rand(几行，几列)

  ```python
  a = np.random.rand((3, 4))
  '''
  [[0.93433278 0.80234233 0.30612868 0.49078802]
   [0.33641166 0.53731781 0.33273095 0.22433124]
   [0.10333016 0.85634791 0.68433399 0.62479299]]
  '''
  ```

+ 产生给定范围均匀分布的整数：np.random.randint(起始，结束，size=(几行，几列))

  ```python
  a = np.random.randint(1,100,size=(2,3))'''[[22 93 48] [92 54 16]]'''
  ```

+ 产生给定范围均匀分布的浮点数：np.random.uniform(low=起始，high=结束，size=(几行，几列))

  ```python
  np.random.uniform(low=1,high=100,size=(2,3))'''[[21.56554585 92.19933024 53.07555868] [11.60883139 19.41117457 37.84024007]]'''
  ```



### 统计相关函数

+ 求和（根据axis的不同，可以求总和、每一列和、每一行和）：数组.sum()

  ```python
  arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])# 求总和ssum = arr.sum() # 45# 求每一列和lsum = arr.sum(axis=0) # [12 15 18]# 求每一行和hsum = arr.sum(axis=1) # [6 15 24]
  ```

+ 求均值（根据axis的不同，可以求总均值、每一列均值、每一行均值）：数组.mean()

  ```python
  arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])# 求总均值smean = arr.mean() # 5.0# 求每一列均值lmean = arr.mean(axis=0) # [4. 5. 6.]# 求每一行均值hmean = arr.mean(axis=1) # [2. 5. 8.]
  ```

+ 累计求和，也就是每一个数都等于等于上一个数加上本身的和：数组.cumsum()

  ```python
  arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])# 常规累计求和smean = arr.cumsum() # [ 1  3  6 10 15 21 28 36 45]# 列累计求和lmean = arr.cumsum(axis=0) # [[ 1  2  3] [ 5  7  9] [12 15 18]]# 行累计求和hmean = arr.cumsum(axis=1) # [[ 1  3  6] [ 4  9 15] [ 7 15 24]]
  ```

+ 求最大值，可以根据axis求出列或者行的最大值：数组.max()



### 线性代数

+ 矩阵乘法，要求第一个矩阵的列数等于第二个矩阵的行数：np.dot(数组1，数组2)

  ```python
  arr1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])arr2 = np.array([[5], [6], [7]])a = np.dot(arr1, arr2)'''[[ 38] [ 92] [146]]'''
  ```

+ 矩阵转置，将矩阵的行变列，列变行：np.transpose(数组)

  ```python
  arr1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])a = np.transpose(arr1)
  ```

+ 矩阵（方阵）求逆，求与该方阵相乘等于E单位矩阵:np.linalg.inv(数组)

  ```python
  arr1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
  arr1_inv = np.linalg.inv(arr1)
  ```

+ 取出矩阵的对角线元素：np.diag(数组)



## Pandas

import pandas as pd

### Series

#### 创建Series

通过pd.Series(data,index,dtype,name)创建。Series的索引默认是1,2,3...，可以在创建时加上index=['a','b',...]来指定索引值。

Series内的data可以是列表、字典、numpy数组等等。原始数据是字典时索引为字典的key。

```python
## 普通创建
series1 = pd.Series([2.8,3.01,8.59])
## 自定义索引和name创建
series2 = pd.Series([2.8,3.01,8.59],index=['a','b','c'],name='This is series')
## 字典作为原始数据
series3 = pd.Series({'北京':2.8,'上海':1.6,'广州':2.1,'深圳':5.1})
```

#### Series常用属性

+ values：以数组的形式输出Series对象的所有元素值
+ index：以数组的形式输出Seires对象的所有索引值
+ dtypes：输出Series对象的数据类型
+ ndim：输出Series对象对象的维度

#### Series数据的获取

+ 可以通过索引获取：series1[0]
+ 还可以进行切片：series1[0:3]   ## 注意这里的切片也是不包含结束位置
+ 还可以通过自定义索引：series3['北京']
+ 自定义索引也可以进行切片：series3['北京','广州']

#### Series数据的修改

+ 直接通过索引修改：series1[0]=100
+ 直接通过索引删除：series3.drop(['北京','广州'],replace=True)
+ 将一个Series添加到另一个Series 的后面：series3.append(series4)



### DataFrame

DataFrame类似于excel表和数据库中的表，可以将DataFrame理解为多个Series数据组成

#### DataFrame的创建

使用pd.DataFrame(data,index,dtype,columns)来创建。与Series一样，data可以是列表、Numpy中的数组或者字典。columns代表列名或者列标签

```python
## 使用嵌套列表创建list1 = [['张三', 18, '男'], ['李四', 19, '男'], ['王五', 18, '女']]df1 = pd.DataFrame(list1, columns=['姓名', '年龄', '性别'])## df1 = ##    姓名  年龄 性别## 0  张三  18  男## 1  李四  19  男## 2  王五  18  女## 使用字典创建df2 = pd.DataFrame({'姓名':['张三','李四','王五'],'年龄':[18,19,18],'性别':['男','男','女']})## df2 = ##    姓名  年龄 性别## 0  张三  18  男## 1  李四  19  男## 2  王五  18  女
```

#### DataFrame的属性

+ values：以numpyarray的形式输出所有值
+ shape：输出形状
+ dtypes：输出数据类型
+ columns：输出列名，可以通过.tolist()转换成列表
+ ndim：输出维数
+ size：输出大小
+ index：输出索引值，通过tolist()转换成列表



### Pandas读取csv数据

使用pd.read_csv(文件路径)来读取csv文件，读出来的数据是DadaFrame形式的，有着DataFrame的属性

可以先导入os包，使用os.chdir(路径)来规定当前文件所在位置，后续使用read_csv时就只写文件名即可，不用写路径。

参数有：

+ 第一个参数必填的文件路径
+ encoding：文件编码方式，默认是utf-8，若文件含有中文则需要设置为gbk
+ dtype：设定每一列数据的类型，例如id是数字默认读取为int类型，我们通过dtype={'id': str}将id设置为读取成str类型
+ nrows：设定读取的行数
+ na_values：设定缺失值，数据中通常使用-1作为缺失值，我们可以通过设置na_values=-1来使得读取出来的所有-1都变成NAN
+ header：设置表头，默认是0也就是设置第一行为表头



### Pandas读取excel数据

使用pd.read_excel(文件路径)来读取excel文件

可以先导入os包，使用os.chdir(路径)来规定当前文件所在位置，后续使用read_excel时就只写文件名即可，不用写路径。

参数与上面读取csv一致，多了一个sheet_name指定读取的是哪个表



### Pandas保存数据

+ 保存为csv文件：数据.to_csv(‘文件名.csv’,index = False)
+ 保存为excel文件：数据.to_excel(‘文件名.excel’,index = False)



### Pandas筛选数据

对从csv或者excel文件中读取出来的数据进行筛选。

读取出来的数据是DataFrame类型的，可以使用切片等方式进行筛选，这里不做赘述。下面介绍loc和iloc的用法

#### loc函数筛选数据

基本语法：数据.loc[行标签或行条件，列标签]

注意loc后面跟的是方括号不是小括号

```python
order = pd.read_csv('911.csv')
# 例如筛选从0到3行的列标签为lng和lat的数据：
order.loc[0:3,['lng','lat']]
#         lat        lng
#0  40.297876  -75.581294
#1  40.258061  -75.264680
#2  40.121182  -75.351975
#3  40.116153  -75.343513
# 筛选第3行和第7行的列标签为lng和lat的数据：
order.loc[[3,7],['lng','lat']]
# 筛选lat为40.116153的列标签为lng和lat的数据：
order.loc[order['lat']==40.116153,['lng','lat']]
```



#### iloc筛选数据

基本语法：数据.iloc[行索引，列索引]

它与loc的区别是loc是行标签也就是loc可以取到右边的数，iloc是行索引也就是不能取到右边的数

```python
order = pd.read_csv('911.csv')
# 筛选从0到2行列从1到2列的数据：
order.iloc[0:2,1:2]
#         lng
#0  -75.581294
#1  -75.264680
```



#### 区间筛选

基本语法：数据[‘列名’].between(左值，右值，inclusive=True/False)，为True表示包含左值和右值，False表示不包含左值和右值

```python
order = pd.read_csv('911.csv')
# 筛选lng在-76到-73之间的数据：
order[['lat','lng']][order['lng'].between(-76,-73,inclusive=True)]
```

#### 多条件筛选

基本语法：数据\[\[列标签]][(条件1) & (条件2) & (条件3) ....]

```python
order = pd.read_csv('911.csv')
# 筛选lng等于-75.343513且lat等于40.116153的数据
order[['lat','lng']][(order['lat']==40.116153)&(order['lng']==-75.343513)]
```

#### 字符串筛选（是否包含在规定的字符串组中）

基本语法：数据[列标签].isin([字符串1，字符串2，...])

#### 字符串筛选（是否含有规定的字符）

基本语法：数据[列标签].str.contains(字符)



### Pandas增删改查

+ 增加一列：数据[列名] = xxx

+ 删除列：数据.drop([列名]，axis=1，inplace=True/False)为True表示作用在原数据上，为False 表示不作用在原数据上

+ 插入新的一列数据：数据.insert(插入在第几列，插入后的列名称，插入的数据)

  ```python
  # 例如将emp_id这一列插入到数据的第一列上去：mid = order['emp_mid']order.drop(['emp_mid'],axis=1,inplace=True)order.insert(0,'mid',mid)
  ```

+ 删除行：数据.drop(labels=[行标签]，axis=0，inplace=True/False)

+ 修改数据：先筛选出来指定的数据，再赋值进行修改

+ 修改列名称：数据.rename(columns={原名称：修改后名称},inplace=True)

+ 修改行标签：数据.rename(index={原标签：修改后标签}，inplace=True)




### Pandas数据整合

+ 自然整合（按照index相同的行整合到一起）：**pd.concat([数据1，数据2，...]，axis=1，join='inner'/'outer')**  inner表示交集多出来的行删除，outer表示并集，多出来的行为NaN
+ 自然整合（将数据直接加在最后一行）：**pd.concat([数据1，数据2，...]，axis=0，ignore_index=True/False)**  True表示忽略原来的行索引重新创建行索引，False表示保留原来的行索引
+ 按指定键整合：**pd.merge(left=数据1，right=数据2，how='right/left/outer/inner'，left_on='数据1的指定键'，right_on='数据2的指定键')**  right表示将右边的数据全输出，left表示将左边的数据全输出，outer表示全输出，inner表示只输出能匹配上的



### Pandnas数据排序

**数据.sort_values([列名1,列名2，....]，ascending=True，na_position=‘last’，inplace=True)**

ascending代表升序或者降序，True为升序，False为降序。

na_position表示空值的摆放位置，last表示空值放在最后，first放开头



### Pandas重置索引

**数据.reset_index(drop=True,inplace=True)**



### Pandas数据求中值均值等

**数据.describe()**  就会展示出所有float或者int类型的数据的数量count、均值mean、标准差str、最小值min、25/50/75中位数、最大值max

也可以：数据[列名].describe() 展示出指定列的计算数据

如果想要对字符串类型的进行计算数据：**数据[列名].describe(include=['object'])**，就会展示数据的数量count、不同值的数量unique、出现次数最多的字符串top、出现的最大次数freq



### Pandas分组聚合

#### Pandas分组

**数据.groupby([列名1，列名2])**   按照指定的列名分组

分组后可以按照分好的组分别计算组内的均值mean、中值median、最大值max、最小值min、总个数count/size、求总和sum

#### Pandas聚合

**数据或分组后的数据.agg([np.mean,np,sum,....])**  列表内可以填np的任意数据处理函数，最后会返回分组对象的这些值.

拿出聚合后的数据通常需要使用到层次索引，层次索引用元组()的形式进行包裹

还可以用字典的形式规定哪些列用哪些方式处理：**数据或分组后的数据.agg({'列名1':np方法，'列名2':np方法})**

或者使用apply：**数据或分组后的数据.apply([np.mean,np,sum,....],axis=0)**

**最后，这里进行数据处理的方式不一定只有numpy的函数，还可以自定义函数或者lamda函数进行数据处理**

